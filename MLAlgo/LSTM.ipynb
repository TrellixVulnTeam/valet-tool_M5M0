{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "                # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hours   Minutes   Seconds   Latency      Cost  Reliability    Friday  \\\n",
      "0 -0.214634 -1.641064 -0.570284  0.398253 -1.799170     0.064093 -0.400349   \n",
      "1  1.092639 -1.007746  0.051433 -0.079609 -1.738793     0.064093 -0.400349   \n",
      "2  0.075871 -1.180469  0.158475 -0.406889  0.817158     0.064093 -0.400349   \n",
      "3 -0.069382  1.180082 -0.012426 -0.406794  0.314018     0.064093 -0.400349   \n",
      "4 -0.940897  1.180082 -1.456998  0.341495  0.384458     0.064093 -0.400349   \n",
      "\n",
      "     Monday  Saturday    Sunday  ...  Server_4.0  Server_5.0  Server_6.0  \\\n",
      "0 -0.435389 -0.392927 -0.402323  ...    -0.31139    2.577480   -0.388116   \n",
      "1 -0.435389 -0.392927 -0.402323  ...    -0.31139    2.577480   -0.388116   \n",
      "2 -0.435389 -0.392927 -0.402323  ...    -0.31139   -0.387967   -0.388116   \n",
      "3 -0.435389 -0.392927 -0.402323  ...    -0.31139   -0.387967   -0.388116   \n",
      "4 -0.435389 -0.392927 -0.402323  ...    -0.31139   -0.387967   -0.388116   \n",
      "\n",
      "   Server_7.0  Server_8.0  Tactic_1.0  Tactic_2.0  Tactic_3.0  Tactic_4.0  \\\n",
      "0   -0.389043   -0.380283    1.972332   -0.498444   -0.497559    -0.49892   \n",
      "1   -0.389043   -0.380283    1.972332   -0.498444   -0.497559    -0.49892   \n",
      "2   -0.389043   -0.380283   -0.507003   -0.498444    2.009769    -0.49892   \n",
      "3   -0.389043   -0.380283   -0.507003   -0.498444    2.009769    -0.49892   \n",
      "4   -0.389043    2.629561   -0.507003   -0.498444   -0.497559    -0.49892   \n",
      "\n",
      "   Tactic_5.0  \n",
      "0   -0.498035  \n",
      "1   -0.498035  \n",
      "2   -0.498035  \n",
      "3   -0.498035  \n",
      "4    2.007846  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = read_csv('dummy.csv')\n",
    "dataset= dataset.drop(columns=[\"newCol\",\"ID\"])\n",
    "values = dataset.values\n",
    "print(dataset.head(5))\n",
    "\n",
    "validation = read_csv('dummy_validate.csv')\n",
    "validation= validation.drop(columns=[\"newCol\",\"ID\"])\n",
    "values_validation = validation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1  -0.214634  -1.641064  -0.570284   0.398253   -1.79917   0.064093   \n",
      "\n",
      "   var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  ...  var20(t-1)  var21(t-1)  \\\n",
      "1  -0.400349  -0.435389  -0.392927   -0.402323  ...   -0.389043   -0.380283   \n",
      "\n",
      "   var22(t-1)  var23(t-1)  var24(t-1)  var25(t-1)  var26(t-1)   var4(t)  \\\n",
      "1    1.972332   -0.498444   -0.497559    -0.49892   -0.498035 -0.079609   \n",
      "\n",
      "    var5(t)   var6(t)  \n",
      "1 -1.738793  0.064093  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "reframed = series_to_supervised(values, 1, 1)\n",
    "reframed_validation = series_to_supervised(values_validation, 1, 1)\n",
    "\n",
    "reframed.drop(reframed.columns[[26,27,28,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51]], axis=1, inplace=True)\n",
    "reframed_validation.drop(reframed_validation.columns[[26,27,28,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51]], axis=1, inplace=True)\n",
    "print(reframed.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36761, 1, 26) (36761, 3) (9190, 1, 26) (9190, 3)\n"
     ]
    }
   ],
   "source": [
    "train = reframed.values\n",
    "test = reframed_validation.values\n",
    "\n",
    "train_X, train_y = train[:, :-3], train[:,-3:]\n",
    "test_X, test_y = test[:, :-3], test[:,-3:]\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36761 samples, validate on 9190 samples\n",
      "Epoch 1/20\n",
      "36761/36761 [==============================] - 6s 173us/step - loss: 1.0056 - val_loss: 0.9781\n",
      "Epoch 2/20\n",
      "36761/36761 [==============================] - 3s 95us/step - loss: 1.0053 - val_loss: 0.9781\n",
      "Epoch 3/20\n",
      "36761/36761 [==============================] - 4s 100us/step - loss: 1.0050 - val_loss: 0.9784\n",
      "Epoch 4/20\n",
      "36761/36761 [==============================] - 4s 106us/step - loss: 1.0046 - val_loss: 0.9789\n",
      "Epoch 5/20\n",
      "36761/36761 [==============================] - 3s 93us/step - loss: 1.0040 - val_loss: 0.9796\n",
      "Epoch 6/20\n",
      "36761/36761 [==============================] - 4s 108us/step - loss: 1.0033 - val_loss: 0.9804\n",
      "Epoch 7/20\n",
      "36761/36761 [==============================] - 3s 84us/step - loss: 1.0025 - val_loss: 0.9813\n",
      "Epoch 8/20\n",
      "36761/36761 [==============================] - 3s 83us/step - loss: 1.0015 - val_loss: 0.9825\n",
      "Epoch 9/20\n",
      "36761/36761 [==============================] - 4s 100us/step - loss: 1.0004 - val_loss: 0.9838\n",
      "Epoch 10/20\n",
      "36761/36761 [==============================] - 3s 85us/step - loss: 0.9992 - val_loss: 0.9854\n",
      "Epoch 11/20\n",
      "36761/36761 [==============================] - 3s 83us/step - loss: 0.9977 - val_loss: 0.9873\n",
      "Epoch 12/20\n",
      "36761/36761 [==============================] - 3s 83us/step - loss: 0.9961 - val_loss: 0.9895\n",
      "Epoch 13/20\n",
      "36761/36761 [==============================] - 3s 93us/step - loss: 0.9942 - val_loss: 0.9920\n",
      "Epoch 14/20\n",
      "36761/36761 [==============================] - 3s 85us/step - loss: 0.9922 - val_loss: 0.9948\n",
      "Epoch 15/20\n",
      "36761/36761 [==============================] - 3s 84us/step - loss: 0.9899 - val_loss: 0.9978\n",
      "Epoch 16/20\n",
      "36761/36761 [==============================] - 3s 95us/step - loss: 0.9875 - val_loss: 1.0011\n",
      "Epoch 17/20\n",
      "36761/36761 [==============================] - 4s 107us/step - loss: 0.9849 - val_loss: 1.0047\n",
      "Epoch 18/20\n",
      " 7992/36761 [=====>........................] - ETA: 3s - loss: 0.8483"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True,input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(LSTM(units=30, return_sequences=True))\n",
    "model.add(LSTM(units=30))\n",
    "model.add(Dense(units=3))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = read_csv('dummy_1.csv')\n",
    "test_dataset= test_dataset.drop(columns=[\"newCol\",\"ID\"])\n",
    "test_values = test_dataset.values\n",
    "reframed_test = series_to_supervised(test_values, 1, 1)\n",
    "reframed_test.drop(reframed_test.columns[[26,27,28,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51]], axis=1, inplace=True)\n",
    "testset = reframed_test.values\n",
    "testset_X, testset_y = testset[:, :-3], testset[:,-3:]\n",
    "testdataReshaped = testset_X.reshape((testset_X.shape[0], 1, testset_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yhat = model.predict(testdataReshaped)\n",
    "\n",
    "print(yhat)\n",
    "dataset = pd.DataFrame({'predicted_Latency': yhat[:, 0], 'predicted_Cost': yhat[:, 1],\n",
    "                       'predicted_Reliability': yhat[:, 2]})\n",
    "dataset['predicted_Reliability'].loc[dataset['predicted_Reliability'] >0.5] = 1\n",
    "dataset['predicted_Reliability'].loc[dataset['predicted_Reliability'] <0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [test_dataset, dataset]\n",
    "result = pd.concat(frames,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result.head(10)\n",
    "result.to_csv('predictions_LSTM.csv', sep=',', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testset_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
